{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import networkx as nx\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import ndlib.models.epidemics as ep\n",
    "import ndlib.models.ModelConfig as mc\n",
    "\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import cpu_count\n",
    "import pickle\n",
    "#mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some set of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_datasets = '../datasets/'\n",
    "path_to_uniform_data = '../data/'\n",
    "path_to_output = '../output/'\n",
    "path_to_samples = '../samples/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graph_data(filename, sep=',', header=None, skiprows=0):\n",
    "    edgelist = pd.read_csv(os.path.join(path_to_datasets, filename), sep=sep, skiprows=skiprows, header=header, names=['source', 'target'])\n",
    "    edgelist.to_csv(os.path.join(path_to_uniform_data, filename), index=False, header=None)\n",
    "    return nx.from_pandas_edgelist(edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citeseer = read_graph_data('citeseer.cites', sep='\\t')\n",
    "deezer_europe = read_graph_data('deezer_europe_edges.csv', header=0)\n",
    "lastfm_asia = read_graph_data('lastfm_asia_edges.csv', header=0)\n",
    "cora = read_graph_data('cora.cites', sep='\\t')\n",
    "email_Eu_core = read_graph_data('email-Eu-core.txt', sep=' ')\n",
    "fb_0 = read_graph_data('0.edges', sep=' ')\n",
    "fb_1 = read_graph_data('107.edges', sep=' ')\n",
    "fb_2 = read_graph_data('348.edges', sep=' ')\n",
    "fb_3 = read_graph_data('414.edges', sep=' ')\n",
    "fb_4 = read_graph_data('686.edges', sep=' ')\n",
    "fb_5 = read_graph_data('698.edges', sep=' ')\n",
    "fb_6 = read_graph_data('1684.edges', sep=' ')\n",
    "fb_7 = read_graph_data('1912.edges', sep=' ')\n",
    "fb_8 = read_graph_data('3437.edges', sep=' ')\n",
    "fb_9 = read_graph_data('3980.edges', sep=' ')\n",
    "email_univ = read_graph_data('email-univ.edges', sep=' ')\n",
    "fb_company = read_graph_data('fb-pages-company.edges', header=0)\n",
    "fb_food = read_graph_data('fb-pages-food.edges')\n",
    "fb_politician = read_graph_data('fb-pages-politician.edges')\n",
    "fb_public_figure = read_graph_data('fb-pages-politician.edges')\n",
    "fb_tvshow = read_graph_data('fb-pages-tvshow.edges')\n",
    "soc_anybeat = read_graph_data('soc-anybeat.edges', sep=' ')\n",
    "soc_hamsterster = read_graph_data('soc-hamsterster.edges', sep=' ', skiprows=2)\n",
    "soc_wiki_vote = read_graph_data('soc-wiki-Vote.mtx', sep=' ', skiprows=2)\n",
    "cit_DBLP = read_graph_data('cit-DBLP.edges', sep=' ', skiprows=2)\n",
    "\n",
    "# list_of_graphs = [citeseer, deezer_europe, lastfm_asia, cora, email_Eu_core,\n",
    "#                   fb_0, fb_1, fb_2, fb_3, fb_4, fb_5, fb_6, fb_7, fb_8, fb_9,\n",
    "#                   email_univ, fb_company, fb_food, fb_politician, fb_public_figure,\n",
    "#                   fb_tvshow, soc_anybeat, soc_hamsterster, soc_wiki_vote, cit_DBLP]\n",
    "# len(list_of_graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph classification dataset for benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zaikoval/Documents/Work/regression-on-sampling/datasets\n",
      "--2020-08-30 12:54:56--  http://nrvis.com/download/data/labeled/REDDIT-BINARY.zip\n",
      "Resolving nrvis.com (nrvis.com)... 173.236.156.25\n",
      "Connecting to nrvis.com (nrvis.com)|173.236.156.25|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9924710 (9,5M) [application/zip]\n",
      "Saving to: ‘REDDIT-BINARY.zip’\n",
      "\n",
      "REDDIT-BINARY.zip   100%[===================>]   9,46M  4,44MB/s    in 2,1s    \n",
      "\n",
      "2020-08-30 12:54:59 (4,44 MB/s) - ‘REDDIT-BINARY.zip’ saved [9924710/9924710]\n",
      "\n",
      "Archive:  REDDIT-BINARY.zip\n",
      "  inflating: REDDIT-BINARY.edges     \n",
      "  inflating: readme.html             \n",
      "  inflating: REDDIT-BINARY.graph_idx  \n",
      "  inflating: REDDIT-BINARY.graph_labels  \n",
      "  inflating: REDDIT-BINARY.readme    \n",
      "/home/zaikoval/Documents/Work/regression-on-sampling/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd ../datasets/\n",
    "!wget http://nrvis.com/download/data/labeled/REDDIT-BINARY.zip\n",
    "!unzip REDDIT-BINARY.zip\n",
    "%cd ../notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.read_csv(os.path.join(path_to_datasets, 'REDDIT-BINARY.edges'), header=None, names=['source', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_graph = nx.from_pandas_edgelist(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_idx = pd.read_csv(os.path.join(path_to_datasets, 'REDDIT-BINARY.graph_idx'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ec0c2a3e8a4cd3b1337837bfdb36eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "graphs = list()\n",
    "for i in tqdm(graph_idx[0].unique()):\n",
    "    set_of_nodes = graph_idx[graph_idx[0] == i].index + 1\n",
    "    subgraph = nx.subgraph(full_graph, set_of_nodes)\n",
    "    connected_subgraph = nx.subgraph(full_graph, max(nx.connected_components(subgraph), key=len)) #extract max connected subgraph\n",
    "    graphs.append(connected_subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = graphs[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f4f7759c504f66b3918f05d6a2f535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaikoval/anaconda3/lib/python3.7/site-packages/ndlib/models/DiffusionModel.py:170: UserWarning: The fraction_infected value is too low given the number of nodes of the selected graph: a single node will be set as infected\n",
      "  \"The fraction_infected value is too low given the number of nodes of the selected graph: a \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6faf5fe56cd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0miterations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-c2cba426079a>\u001b[0m in \u001b[0;36mcalc_iter\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'node_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlen_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlist_of_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ndlib/models/epidemics/SIModel.py\u001b[0m in \u001b[0;36miteration\u001b[0;34m(self, node_status)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mu_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0meventp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredecessors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#считаем ndlib for them 1h40m\n",
    "iterations = []\n",
    "for elem in tqdm(graphs):\n",
    "    iterations.append(calc_iter(elem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переписать функцию с параметром parallelized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e9fd96ae40422c9a786488bc6acd31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaikoval/anaconda3/lib/python3.7/site-packages/ndlib/models/DiffusionModel.py:170: UserWarning: The fraction_infected value is too low given the number of nodes of the selected graph: a single node will be set as infected\n",
      "  \"The fraction_infected value is too low given the number of nodes of the selected graph: a \"\n",
      "/home/zaikoval/anaconda3/lib/python3.7/site-packages/ndlib/models/DiffusionModel.py:170: UserWarning: The fraction_infected value is too low given the number of nodes of the selected graph: a single node will be set as infected\n",
      "  \"The fraction_infected value is too low given the number of nodes of the selected graph: a \"\n",
      "/home/zaikoval/anaconda3/lib/python3.7/site-packages/ndlib/models/DiffusionModel.py:170: UserWarning: The fraction_infected value is too low given the number of nodes of the selected graph: a single node will be set as infected\n",
      "  \"The fraction_infected value is too low given the number of nodes of the selected graph: a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "iterations = [] \n",
    "\n",
    "with mp.Pool(cpu_count()) as p:\n",
    "    iterations = list(tqdm(p.imap(calc_iter, graphs, chunksize=6), total=len(graphs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(iterations).to_csv(os.path.join(path_to_output, 'ndlib/ndlib.csv'), index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in tqdm(graphs):#считам motif distribution for them\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters_list = [] # считаем для каждого из них ndlib количество итераций до заражения\n",
    "for elem in tqdm(graphs_list): # make it with multiprocessing\n",
    "    iters_list.append((elem, calc_iter(elem)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in tqdm(graphs_list): # считаем для них распределение мотивов\n",
    "    gt.extract_motifs(elem, 4, path_to_graphs=path_to_uniform_data, path_to_output=path_to_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in tqdm(graphs_list): # сэмплируем из них 10 графов с примерно половиной количества нод\n",
    "    \n",
    "    G = nx.from_pandas_edgelist(\n",
    "        pd.read_csv(os.path.join(path_to_uniform_data, graph), names=['source', 'target']))\n",
    "    \n",
    "    for j in range(20):\n",
    "        extra_hop = set()\n",
    "        first_node = np.random.choice(G.nodes()) # not just random, but only among low degree\n",
    "        \n",
    "        extra_hop = extra_hop.union(list(nx.neighbors(G, first_node)))\n",
    "        i=1\n",
    "\n",
    "        while (i<4) and (len(extra_hop)<G.number_of_nodes()):\n",
    "            i+=1\n",
    "            for node in extra_hop:\n",
    "                 extra_hop = extra_hop.union(nx.neighbors(G, node))\n",
    "\n",
    "            nx.to_pandas_edgelist(nx.subgraph(G, extra_hop)).to_csv(\n",
    "            os.path.join(path_to_samples, graph+'_h{}_s{}.csv'.format(i,j+1)),\n",
    "            header=None,\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для каждого из них считаем распределения и усредняем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем датасет и делаем кроссвалидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>153</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>165</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>168</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>172</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     source  target\n",
       "0         1     168\n",
       "1         2      58\n",
       "2         3      58\n",
       "3         4      58\n",
       "4         5      79\n",
       "..      ...     ...\n",
       "233     144     212\n",
       "234     153     171\n",
       "235     165     167\n",
       "236     168     172\n",
       "237     172     202\n",
       "\n",
       "[238 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.to_pandas_edgelist(graphs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iter(g):    \n",
    "    \n",
    "    len_nodes = len(g.nodes())\n",
    "    \n",
    "    list_of_iter = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        model = ep.SIModel(g)\n",
    "        cfg = mc.Configuration()\n",
    "        cfg.add_model_parameter('beta', 0.2)\n",
    "        cfg.add_model_parameter(\"percentage_infected\", 0.01)\n",
    "        model.set_initial_status(cfg)\n",
    "    \n",
    "        iteration = model.iteration() #initialization\n",
    "    \n",
    "        while (iteration['node_count'][1]<len_nodes):\n",
    "            iteration = model.iteration()\n",
    "        \n",
    "        list_of_iter.append(iteration['iteration'])\n",
    "        \n",
    "    return np.mean(list_of_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_size_n_dens(mdf):\n",
    "    path_to_gph = '/Users/zaikoval/Downloads/graphs_5types/graphs'\n",
    "    for idx in mdf.index:\n",
    "        graph = nx.from_pandas_edgelist(pd.read_csv(os.path.join(path_to_gph, '-'+str(idx)+'.csv'), names=['source', 'target']))\n",
    "        n = graph.number_of_nodes()\n",
    "        e = graph.number_of_edges()\n",
    "        mdf.loc[idx, 'nodes'] = n\n",
    "        mdf.loc[idx, 'edges'] = e\n",
    "        mdf.loc[idx, 'density'] = 2*e/(n*(n-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7fcd38043610>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.relabel_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTscanner:\n",
    "    \"\"\"\n",
    "    Python wrapper for GTscanner algorithm\n",
    "    \"\"\" \n",
    "    \n",
    "    def extract_motifs(self, graph, size, random=10, algo='gtrie /home/zaikoval/Documents/Work/gtscanner/gtries/undir5.gt ', threads=8, output=''):\n",
    "        \"\"\"\n",
    "        Calls execution of GTscanner algorithm with parameters:\n",
    "        \n",
    "        graph - path to the txt file of graph\n",
    "        \n",
    "        size - size of motif to extract \n",
    "        \n",
    "        random - number of random graph to generate (better 100+)\n",
    "        \"\"\"\n",
    "        import os\n",
    "        \n",
    "        path_to_examples = '../output/gtscanner/temp/'\n",
    "        graph_data = nx.to_pandas_edgelist(graph)\n",
    "        unq_elem = np.unique(graph_data)\n",
    "        graph_data = graph_data.applymap(lambda x: np.where(x == unq_elem)[0][0]+1)\n",
    "        prep_data = os.path.join(path_to_examples, 'temp.txt')\n",
    "        graph_data.to_csv(prep_data, sep=' ', header=None, index=False)\n",
    "        \n",
    "        cmd = '/home/zaikoval/Documents/Work/gtscanner_modified/./GTScanner -s ' \\\n",
    "        + str(size) \\\n",
    "        + ' -m ' + algo \\\n",
    "        + ' -g ' + os.path.abspath(prep_data) \\\n",
    "        + ' -f simple' \\\n",
    "        + ' -t html' \\\n",
    "        + ' -o ' + output + filename + '_' + str(size) +'.html'\\\n",
    "        + ' -r ' + str(random) \\\n",
    "        + ' -th ' + str(threads)\n",
    "        answer = os.popen(cmd).read()\n",
    "        print(answer)\n",
    "    \n",
    "    def extract_result(self, file='/home/zaikoval/Documents/Work/gtscanner/results/result.html'):\n",
    "        from bs4 import BeautifulSoup\n",
    "        \n",
    "        adjs = []\n",
    "        freqs = []\n",
    "        zs = []\n",
    "        \n",
    "        soup = BeautifulSoup(open(file).read())\n",
    "        content = soup.find_all('tr')[1:]\n",
    "        \n",
    "        for motif in content:\n",
    "            adjs.append(np.matrix([list(x) for x in motif.find('td', attrs={'class':'pre'}).text.split('\\n')], dtype=int))\n",
    "            stats = motif.find_all('td')[2:4]\n",
    "            freqs.append(float(stats[0].text))\n",
    "            zs.append(float(stats[1].text))\n",
    "        \n",
    "        ans = list(zip(adjs, freqs, zs))\n",
    "        return ans\n",
    "    def data_4(self, files=[]):\n",
    "       \n",
    "        stats = []\n",
    "#         path_to_results_4 = '/Users/zaikoval/Documents/GitHub/network-motif-analysis/sampling/hop_result_4/'\n",
    "        \n",
    "        for item in files:\n",
    "            stats.append((item.split('/')[-1][:-7],\n",
    "                          self.extract_result(item)))\n",
    "            \n",
    "#         for item in stats:\n",
    "#             item.sort(key=lambda x: int(''.join(list(np.array(x[0]).flatten().astype(str))), base=10))\n",
    "            \n",
    "        pickleFile = open(\"/Users/zaikoval/Documents/GitHub/network-motif-analysis/dict_4.pkl\", 'rb')\n",
    "        dict_4 = pickle.load(pickleFile)\n",
    "        pickleFile.close()\n",
    "        \n",
    "        \n",
    "        i=0\n",
    "        \n",
    "        box_list = []\n",
    "        \n",
    "        for graph in stats:\n",
    "            \n",
    "            dict_4_z = dict(dict_4) \n",
    "            dict_4_f = dict(dict_4)\n",
    "            \n",
    "            \n",
    "            # for 4-motif\n",
    "            for elem in graph[1]:\n",
    "                dict_4_z[str(elem[0])] = 0\n",
    "                dict_4_f[str(elem[0])] = 0\n",
    "                \n",
    "                if (elem[2] not in [float('inf'), float('-inf')]) and (not np.isnan(elem[2])):\n",
    "                    dict_4_z[str(elem[0])] = elem[2]\n",
    "                else: \n",
    "                    dict_4_z[str(elem[0])] = 0\n",
    "                    \n",
    "                if (elem[1] not in [float('inf'), float('-inf')]) and (not np.isnan(elem[2])):\n",
    "                    dict_4_f[str(elem[0])] = elem[1]\n",
    "                else: \n",
    "                    dict_4_f[str(elem[0])] = 0\n",
    "            \n",
    "            z_scores_4 = list(dict_4_z.values())\n",
    "            freqs_4 = list(dict_4_f.values())\n",
    "            \n",
    "            sum_of_freqs_4 = np.sum(freqs_4)\n",
    "            normed_freqs_4 = freqs_4 / sum_of_freqs_4\n",
    "            \n",
    "            normed_z_scores_4 = z_scores_4 / np.sqrt(np.sum([x**2 for x in z_scores_4])) # ыыыыыыыыы\n",
    "         \n",
    "            \n",
    "            box_list.append([graph[0]] + \\\n",
    "                            #list(normed_z_scores_4) + \\\n",
    "                            list(normed_freqs_4))\n",
    "            \n",
    "        return box_list\n",
    "    \n",
    "gt = GTscanner()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
